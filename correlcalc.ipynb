{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Recipe for 'Quick' Computation of two-point correlation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we take galaxy data from a redshift survey. In this paper,\n",
    "we take DR72 VAGC from Kazin *et. al.* [@kazin2010baryonic] to\n",
    "demonstrate the procedure. Typical data from a redshift survey contains\n",
    "list of galaxies with their observed redshift, Right ascension (RA) and\n",
    "declination angles (DEC) that provide the position of each galaxy.\n",
    "Often, a value added catalog limits the magnitude and chooses a specific\n",
    "type of galaxy such as Luminous Red Galaxies - LRGs in DR72 VAGC. There\n",
    "are further parameters in a typical catalog such as magnitude, survey\n",
    "completeness, radial weights etc. In this paper, we shall only make use\n",
    "of the redshift and angular position of each galaxy from the catalog.\n",
    "Survey geometry and distribution are taken in mangle polygon file\n",
    "formats (`.ply`) provided by the respective survey data release. Value\n",
    "added catalogs such as the ones taken from (non-official) SDSS DR72\n",
    "[@dr72vagc] also provide random catalogs. Typically much larger than the\n",
    "galaxy catalog. The procedure provided in this paper can certainly be\n",
    "run on these random catalogs. However, as we will see later to reduce\n",
    "computational effort we can create a smaller random catalog without much\n",
    "loss of accuracy in the final 2pcf result. \\[fig2\\] gives a flowchart of\n",
    "the recipe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<object data=\"http://yoursite.com/the.pdf\" type=\"application/pdf\" width=\"700px\" height=\"700px\">\n",
    "    <embed src=\"http://yoursite.com/the.pdf\">\n",
    "        This browser does not support PDFs. Please download the PDF to view it: <a href=\"http://yoursite.com/the.pdf\">Download PDF</a>.</p>\n",
    "    </embed>\n",
    "</object>\n",
    "\n",
    "![Flow chart of the quick computation recipe](flowchart1 \"fig:\")\n",
    "\\[flowchart1\\]\n",
    "\n",
    "Data Preparation\n",
    "----------------\n",
    "\n",
    "-   Install relevant packages such as `numpy`, `sklearn`, `healpy` and\n",
    "    `pymangle` using `pip` or `conda` package managers.\n",
    "\n",
    "-   Take any existing large scale structure catalogs or create one\n",
    "    yourself by following instructions from (SDSS lss catalog creation\n",
    "    cite)\n",
    "\n",
    "-   Calculate Comoving distance as per the model of your choice\n",
    "    (fiducial cosmology)\n",
    "\n",
    "-   Load data in RAM as 3xNd matrix \\[s,rar,decr\\] (Can choose to pickle\n",
    "    the data or store as ascii file -pickling might not be the best way\n",
    "    for large data files)\n",
    "\n",
    "Random Catalog Preparation\n",
    "--------------------------\n",
    "\n",
    "-   If we use the random catalog given by the survey. calculation of\n",
    "    random-random correlation is similar to the steps above. However,\n",
    "    often it is computationally intensive to calculate for high no. of\n",
    "    random points. So, a method to create a smaller random catalog which\n",
    "    can give reasonably accurate results in comparison to the standard\n",
    "    random catalog.\n",
    "\n",
    "-   All the major surveys provide the survey geometry in form of angular\n",
    "    masks in `fits` and/or `ply` formats. We use mangle polygons\n",
    "    [@hamilton2004scheme] [@swanson2008methods] given by the survey to\n",
    "    create random points.\n",
    "\n",
    "-   pymangle is a python wrapper to a faster `C/C++` code to manipulate\n",
    "    mangle angular masks[@pymangle]. It can create a random catalog with\n",
    "    a specified no. of data points that follow the angular masks\n",
    "    provided by the survey. (One can also specify boundaries to\n",
    "    calculate random points faster and use additional options such as\n",
    "    polygon weights). In this paper, we demonstrate a simple application\n",
    "    without weights etc.\n",
    "\n",
    "-   mangle gives random points in the angular domain only providing RA\n",
    "    and DEC for the random points. We will also need redshift values to\n",
    "    be assigned to these random points. These redshifts need to follow\n",
    "    the survey radial distribution to creating a matching random\n",
    "    catalog. If we are creating a random catalog that is of the same\n",
    "    size as the data catalog then it is easier to re-use the redshifts\n",
    "    of the data and shuffle them to assign to the random catalog points.\n",
    "    This ensures the radial distribution of the random points to be the\n",
    "    same as galaxy catalog.\n",
    "\n",
    "-   If we are to create a random catalog of different size (recommended\n",
    "    to use bigger($\\geq2x$) than the data catalog to reduce the shot\n",
    "    noise.) we can plot the histogram or Kernel density estimator of the\n",
    "    data redshift distribution and create a random catalog that mimics\n",
    "    this distribution. As KDE is a better choice than using a histogram\n",
    "    (reference), we create a random distribution points for redshifts\n",
    "    using the same.\n",
    "\n",
    "Healpix Visualization\n",
    "---------------------\n",
    "\n",
    "-   HealPix (and the wrapper healpy) are extremely useful to visualize\n",
    "    the surveys - Plot surveys\n",
    "\n",
    "-   After creating the random catalog it is good to visually cross-check\n",
    "    if they all indeed follow the supplied geometry. Using Healpix we\n",
    "    can draw the random catalog with random point positions as per the\n",
    "    mask as shown below in \\[fig3\\].\n",
    "\n",
    "    ![Generated random catalog with DR72\n",
    "    mask[]{data-label=\"fig3\"}](plots/rand100k \"fig:\")\\[h\\]\n",
    "\n",
    "Defining distance metric and creating `BinaryTrees`\n",
    "---------------------------------------------------\n",
    "\n",
    "-   Define custom metric in Cython (to improve the speed of\n",
    "    computation) - metric not to be confused with Cosmology metric. This\n",
    "    is to find distance between two points in the galaxy survey. This\n",
    "    depends on the geometry of the Universe (see theory- give citation\n",
    "    to Matsubara 2004) Also write formula for calculation of angle\n",
    "    between two points on a sphere. Use square distance to calculate\n",
    "    faster (reduce sqrt operation) - One needs to take into account that\n",
    "    the formulae are given for $c=1$ and so to get dimensionless numbers\n",
    "    inside $\\sin$ or $\\sinh$ we need to multiply the co-moving distance\n",
    "    with an appropriate factor assuming the current Hubble expansion\n",
    "    rate.\n",
    "\n",
    "-   Create a BallTree with the previously defined custom-metric (Use\n",
    "    squared distance)\n",
    "\n",
    "-   Define distance bins for calculating no. of pairs that fall in the\n",
    "    specified distance radius (Do not forget to use binsq instead of\n",
    "    bins)\n",
    "\n",
    "-   Experiment with leafsize option to improve computation\n",
    "    time/efficiency (ref: jakedvp benchmarking website ref) - talk about\n",
    "    finding points vs. calculation of distance by brute-force\n",
    "\n",
    "Calculation of 2pcf\n",
    "-------------------\n",
    "\n",
    "-   Calculation of data-data pair correlation is done by `np.diff` to\n",
    "    find the number of galaxies in the specific bins. This gives us $DD$\n",
    "    value for the bins.\n",
    "\n",
    "-   Repeat the same procedure for calculating $DD$ with random catalog\n",
    "    to obtain $RR$ (random–random correlation)\n",
    "\n",
    "-   To calculate data-random correlation, we need to find the random\n",
    "    points in the data-tree or vice-versa. This gives us $DR$ ($=RD$)\n",
    "\n",
    "-   Having obtained $DD$, $RR$ and $DR$, using scaling factor\n",
    "    ($N_r/N_d$) we can find the correlation function using the\n",
    "    Landy-Szalay estimator [@landy1993bias] as We use Landy &\n",
    "    Szalay (1993) algorithm to get the two-point correlation function,\n",
    "    $$\\xi (s ;z)=1+\\left(\\frac{N_d}{N}\\right)^2\\frac{DD}{RR}-2\\left(\\frac{N_d}{N}\\right)\\frac{DR}{ RR}$$\n",
    "\n",
    "    where DD, RR, DR are the number of data–data, random–random,\n",
    "    data–random and random–data pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
